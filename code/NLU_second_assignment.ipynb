{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLU second assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1fHnC60G76wrA7AQc3k6R21kuXrSRvEil",
      "authorship_tag": "ABX9TyOcM4gV540gA9tkJNTznZsV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steveazzolin/NLU-second-assignment/blob/main/code/NLU_second_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm1Xis60mart"
      },
      "source": [
        "## NLU second assignment\n",
        "\n",
        "Steve Azzolin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZSrISCkOitB"
      },
      "source": [
        "%%capture\n",
        "!pip install spacy==3.0.3\n",
        "!python -m spacy download en_core_web_sm\n",
        "!git clone https://github.com/steveazzolin/NLU-second-assignment.git"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNOhpUkQnAns"
      },
      "source": [
        "import spacy\n",
        "from spacy.tokens import Span\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-5vAk-rm0Mk"
      },
      "source": [
        "#### conll.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wba-sEzVLUni"
      },
      "source": [
        "In the following cell I included the conll script as provided by prof. Stepanov, with a slight modification in the function `read_corpus_conll`. In particular, I removed the line containing `DOCSTRING` from the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhN13QTLmYAj"
      },
      "source": [
        "import re\n",
        "\n",
        "\"\"\"\n",
        "Modified version of https://pypi.org/project/conlleval/\n",
        "\"\"\"\n",
        "\n",
        "def stats():\n",
        "    return {'cor': 0, 'hyp': 0, 'ref': 0}\n",
        "\n",
        "\n",
        "def evaluate(ref, hyp, otag='O'):\n",
        "    # evaluation for NLTK\n",
        "    aligned = align_hyp(ref, hyp)\n",
        "    return conlleval(aligned, otag=otag)\n",
        "\n",
        "\n",
        "def align_hyp(ref, hyp):\n",
        "    # align references and hypotheses for evaluation\n",
        "    # add last element of token tuple in hyp to ref\n",
        "    if len(ref) != len(hyp):\n",
        "        raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n",
        "\n",
        "    out = []\n",
        "    for i in range(len(ref)):\n",
        "        if len(ref[i]) != len(hyp[i]):\n",
        "            raise ValueError(\"Size Mismatch: ref: {} & hyp: {}\".format(len(ref), len(hyp)))\n",
        "        out.append([(*ref[i][j], hyp[i][j][-1]) for j in range(len(ref[i]))])\n",
        "    return out\n",
        "\n",
        "\n",
        "def conlleval(data, otag='O'):\n",
        "    # token, segment & class level counts for TP, TP+FP, TP+FN\n",
        "    tok = stats()\n",
        "    seg = stats()\n",
        "    cls = {}\n",
        "\n",
        "    for sent in data:\n",
        "\n",
        "        prev_ref = otag      # previous reference label\n",
        "        prev_hyp = otag      # previous hypothesis label\n",
        "        prev_ref_iob = None  # previous reference label IOB\n",
        "        prev_hyp_iob = None  # previous hypothesis label IOB\n",
        "\n",
        "        in_correct = False  # currently processed chunks is correct until now\n",
        "\n",
        "        for token in sent:\n",
        "\n",
        "            hyp_iob, hyp = parse_iob(token[-1])\n",
        "            ref_iob, ref = parse_iob(token[-2])\n",
        "\n",
        "            ref_e = is_eoc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n",
        "            hyp_e = is_eoc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n",
        "\n",
        "            ref_b = is_boc(ref, ref_iob, prev_ref, prev_ref_iob, otag)\n",
        "            hyp_b = is_boc(hyp, hyp_iob, prev_hyp, prev_hyp_iob, otag)\n",
        "\n",
        "            if not cls.get(ref) and ref:\n",
        "                cls[ref] = stats()\n",
        "\n",
        "            if not cls.get(hyp) and hyp:\n",
        "                cls[hyp] = stats()\n",
        "\n",
        "            # segment-level counts\n",
        "            if in_correct:\n",
        "                if ref_e and hyp_e and prev_hyp == prev_ref:\n",
        "                    in_correct = False\n",
        "                    seg['cor'] += 1\n",
        "                    cls[prev_ref]['cor'] += 1\n",
        "\n",
        "                elif ref_e != hyp_e or hyp != ref:\n",
        "                    in_correct = False\n",
        "\n",
        "            if ref_b and hyp_b and hyp == ref:\n",
        "                in_correct = True\n",
        "\n",
        "            if ref_b:\n",
        "                seg['ref'] += 1\n",
        "                cls[ref]['ref'] += 1\n",
        "\n",
        "            if hyp_b:\n",
        "                seg['hyp'] += 1\n",
        "                cls[hyp]['hyp'] += 1\n",
        "\n",
        "            # token-level counts\n",
        "            if ref == hyp and ref_iob == hyp_iob:\n",
        "                tok['cor'] += 1\n",
        "\n",
        "            tok['ref'] += 1\n",
        "\n",
        "            prev_ref = ref\n",
        "            prev_hyp = hyp\n",
        "            prev_ref_iob = ref_iob\n",
        "            prev_hyp_iob = hyp_iob\n",
        "\n",
        "        if in_correct:\n",
        "            seg['cor'] += 1\n",
        "            cls[prev_ref]['cor'] += 1\n",
        "\n",
        "    return summarize(seg, cls)\n",
        "\n",
        "\n",
        "def parse_iob(t):\n",
        "    m = re.match(r'^([^-]*)-(.*)$', t)\n",
        "    return m.groups() if m else (t, None)\n",
        "\n",
        "\n",
        "def is_boc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n",
        "    \"\"\"\n",
        "    is beginning of a chunk\n",
        "\n",
        "    supports: IOB, IOBE, BILOU schemes\n",
        "        - {E,L} --> last\n",
        "        - {S,U} --> unit\n",
        "\n",
        "    :param lbl: current label\n",
        "    :param iob: current iob\n",
        "    :param prev_lbl: previous label\n",
        "    :param prev_iob: previous iob\n",
        "    :param otag: out-of-chunk label\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    boc = False\n",
        "\n",
        "    boc = True if iob in ['B', 'S', 'U'] else boc\n",
        "    boc = True if iob in ['E', 'L'] and prev_iob in ['E', 'L', 'S', otag] else boc\n",
        "    boc = True if iob == 'I' and prev_iob in ['S', 'L', 'E', otag] else boc\n",
        "\n",
        "    boc = True if lbl != prev_lbl and iob != otag and iob != '.' else boc\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    boc = True if iob in ['[', ']'] else boc\n",
        "\n",
        "    return boc\n",
        "\n",
        "\n",
        "def is_eoc(lbl, iob, prev_lbl, prev_iob, otag='O'):\n",
        "    \"\"\"\n",
        "    is end of a chunk\n",
        "\n",
        "    supports: IOB, IOBE, BILOU schemes\n",
        "        - {E,L} --> last\n",
        "        - {S,U} --> unit\n",
        "\n",
        "    :param lbl: current label\n",
        "    :param iob: current iob\n",
        "    :param prev_lbl: previous label\n",
        "    :param prev_iob: previous iob\n",
        "    :param otag: out-of-chunk label\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    eoc = False\n",
        "\n",
        "    eoc = True if iob in ['E', 'L', 'S', 'U'] else eoc\n",
        "    eoc = True if iob == 'B' and prev_iob in ['B', 'I'] else eoc\n",
        "    eoc = True if iob in ['S', 'U'] and prev_iob in ['B', 'I'] else eoc\n",
        "\n",
        "    eoc = True if iob == otag and prev_iob in ['B', 'I'] else eoc\n",
        "\n",
        "    eoc = True if lbl != prev_lbl and iob != otag and prev_iob != '.' else eoc\n",
        "\n",
        "    # these chunks are assumed to have length 1\n",
        "    eoc = True if iob in ['[', ']'] else eoc\n",
        "\n",
        "    return eoc\n",
        "\n",
        "\n",
        "def score(cor_cnt, hyp_cnt, ref_cnt):\n",
        "    # precision\n",
        "    p = 1 if hyp_cnt == 0 else cor_cnt / hyp_cnt\n",
        "    # recall\n",
        "    r = 0 if ref_cnt == 0 else cor_cnt / ref_cnt\n",
        "    # f-measure (f1)\n",
        "    f = 0 if p+r == 0 else (2*p*r)/(p+r)\n",
        "    return {\"p\": p, \"r\": r, \"f\": f, \"s\": ref_cnt}\n",
        "\n",
        "\n",
        "def summarize(seg, cls):\n",
        "    # class-level\n",
        "    res = {lbl: score(cls[lbl]['cor'], cls[lbl]['hyp'], cls[lbl]['ref']) for lbl in set(cls.keys())}\n",
        "    # micro\n",
        "    res.update({\"total\": score(seg.get('cor', 0), seg.get('hyp', 0), seg.get('ref', 0))})\n",
        "    return res\n",
        "\n",
        "\n",
        "def read_corpus_conll(corpus_file, fs=\" \"):\n",
        "    \"\"\"\n",
        "    read corpus in CoNLL format\n",
        "    :param corpus_file: corpus in conll format\n",
        "    :param fs: field separator\n",
        "    :return: corpus\n",
        "    \"\"\"\n",
        "    featn = None  # number of features for consistency check\n",
        "    sents = []  # list to hold words list sequences\n",
        "    words = []  # list to hold feature tuples\n",
        "\n",
        "    for line in open(corpus_file):\n",
        "        if \"-DOCSTART-\" in line:\n",
        "          continue\n",
        "        line = line.strip()\n",
        "        if len(line.strip()) > 0:\n",
        "            feats = tuple(line.strip().split(fs))\n",
        "            if not featn:\n",
        "                featn = len(feats)\n",
        "            elif featn != len(feats) and len(feats) != 0:\n",
        "                raise ValueError(\"Unexpected number of columns {} ({})\".format(len(feats), featn))\n",
        "\n",
        "            words.append(feats)\n",
        "        else:\n",
        "            if len(words) > 0:\n",
        "                sents.append(words)\n",
        "                words = []\n",
        "    return sents\n",
        "\n",
        "\n",
        "def get_chunks(corpus_file, fs=\"\\t\", otag=\"O\"):\n",
        "    sents = read_corpus_conll(corpus_file, fs=fs)\n",
        "    return set([parse_iob(token[-1])[1] for sent in sents for token in sent if token[-1] != otag])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKSaSvhNJSki"
      },
      "source": [
        "Since the goal of the following exercise is to evaluate the performances of Spacy on conll2003, I'll read only the test set, ignoring both the train and validation set. However, including them in the analysis would be straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-diFq6aTpEdI"
      },
      "source": [
        "test = read_corpus_conll(\"NLU-second-assignment/data/test.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFQAo3Plc8xW"
      },
      "source": [
        "## ex01\n",
        "\n",
        ">Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
        ">\n",
        ">- report token-level performance (per class and total)\n",
        "  - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
        "- report CoNLL chunk-level performance (per class and total);\n",
        "  - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "One important caveat of this exercise was the conversion between the [Spacy's annotation scheme](https://spacy.io/models/en) and the [Conll's annotation scheme](https://www.clips.uantwerpen.be/conll2003/ner/annotation.txt). To resolve this inconsistency, I simply translate the two sets of tags with a mapper. In doing this an ambiguity emerged, related to how to handle some particular tags of Spacy, such as *DATE* and *TIME*. In the annotation scheme linked above, dates are not mentioned, suggesting to don't consider this tag at all. But, since this would result in an incomplete mapping between Spacy and Conll I decided to map *DATE* and *TIME* to *O*, since is possible to find in the dataset examples of dates and hours labelled with that token. A similar reasoning can be applied also to other tags mapped to *O*.\n",
        "\n",
        "\n",
        "Moreover, an additional difficulty was to take care of the different tokenization approach. In this case I enforced Spacy to use the conll's tokenization, by overloading the default tokenizer of Spacy. This may result in performances losses, however I noticed that in this dataset this is not the case. An alternative approach would be to re-join tokens, as provided by Spacy, by analyzing the attribute `whitespace_` of `Token`.\n",
        "\n",
        "For token-level performances, I used [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) since provides a handy way for summarizing the most popular classification metrics, whereas for chunk-level performances I used the evaluate script provided by *conll.py*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NVKVzagNCR4"
      },
      "source": [
        "def compose_string_prediction(doc, mapper):\n",
        "  \"\"\"\n",
        "  Convert Doc object into list of NE tags.\n",
        "  Thanks to 'mapper' convert also from Spacy's annotation scheme to Conll's annotation scheme\n",
        "  \"\"\"\n",
        "  assert mapper is not None\n",
        "\n",
        "  ret = []\n",
        "  for t in doc:\n",
        "    tmp = mapper[t.ent_type_]\n",
        "    if t.ent_type_ != \"\" and tmp != \"O\": #if iob tag is O then ent_type_ is \"\"\n",
        "      tmp = t.ent_iob_ + \"-\" + tmp \n",
        "    ret.append(tmp)\n",
        "  return ret"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez2eXgosK9mK",
        "outputId": "4d127f9b-98a9-430d-8d27-7f7bf2ce7787"
      },
      "source": [
        "# mapper to convert from spacy's tags to conll's tags\n",
        "mapper = { \n",
        "    'PERSON':'PER', \n",
        "    'NORP':'MISC', \n",
        "    'LOC':'LOC', \n",
        "    'FAC':'LOC', \n",
        "    'GPE':'LOC', \n",
        "    'ORG':'ORG', \n",
        "    'PRODUCT':'MISC', \n",
        "    'EVENT':'MISC', \n",
        "    'WORK_OF_ART':'O', \n",
        "    'LAW':'O', \n",
        "    'LANGUAGE':'MISC', \n",
        "    'DATE':'O', \n",
        "    'TIME':'O', \n",
        "    'PERCENT':'O', \n",
        "    'MONEY':'O', \n",
        "    'QUANTITY':'O', \n",
        "    'ORDINAL':'O', \n",
        "    'CARDINAL':'O', \n",
        "    '':'O'\n",
        "}\n",
        "\n",
        "\n",
        "def my_tokenizer(txt=\"\"):\n",
        "  \"\"\"\n",
        "  Overload the spacy's tokenization in order to comply to the tokenization of conll.\n",
        "  An alternative approach is to reconstruct the tokens provided by Spacy by analyzing\n",
        "  the whitespace attribute. Here not implemented for timing issues\n",
        "  \"\"\"\n",
        "  return spacy.tokens.Doc(nlp.vocab, my_tokenization)\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = my_tokenizer\n",
        "\n",
        "pred , true , dataset = [] , [] , []\n",
        "conll_pred , conll_true = [] , []\n",
        "for sentence in tqdm(test[:]):\n",
        "  y = [s[3] for s in sentence]\n",
        "  x = \" \".join([s[0] for s in sentence])\n",
        "  my_tokenization = [s[0] for s in sentence]\n",
        "\n",
        "  doc = nlp(x)\n",
        "\n",
        "  #compose prediction/gt vectors for token-level evaluation\n",
        "  pred.extend(compose_string_prediction(doc, mapper))\n",
        "  true.extend(y)\n",
        "\n",
        "  #compose prediction/gt vectors for chunk-level evaluation\n",
        "  preds = compose_string_prediction(doc, mapper)\n",
        "  conll_pred.append([])\n",
        "  conll_true.append([])\n",
        "  for j in range(len(y)):\n",
        "    conll_pred[-1].append((sentence[j][0] , preds[j]))\n",
        "    conll_true[-1].append((sentence[j][0] , y[j]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3453/3453 [00:32<00:00, 106.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqRHmvgNSqb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "96cb48dd-96a6-4443-e531-c2f36a93079b"
      },
      "source": [
        "le = preprocessing.LabelEncoder() #to convert from 'string' to 'int' the prediction vector\n",
        "le.fit(true)\n",
        "\n",
        "print(\"Overall performances per-class:\")\n",
        "print(classification_report(le.transform(true), le.transform(pred), target_names=le.classes_))\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Chunk-level performances:\")\n",
        "pd_tbl = pd.DataFrame().from_dict(evaluate(conll_true, conll_pred), orient='index')\n",
        "pd_tbl.round(decimals=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall performances per-class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.77      0.71      0.74      1668\n",
            "      B-MISC       0.77      0.55      0.64       702\n",
            "       B-ORG       0.50      0.30      0.38      1661\n",
            "       B-PER       0.79      0.61      0.69      1617\n",
            "       I-LOC       0.58      0.66      0.61       257\n",
            "      I-MISC       0.59      0.34      0.43       216\n",
            "       I-ORG       0.42      0.52      0.46       835\n",
            "       I-PER       0.82      0.76      0.78      1156\n",
            "           O       0.95      0.98      0.96     38323\n",
            "\n",
            "    accuracy                           0.91     46435\n",
            "   macro avg       0.69      0.60      0.63     46435\n",
            "weighted avg       0.90      0.91      0.90     46435\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Chunk-level performances:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.63</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.59</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          p     r     f     s\n",
              "MISC   0.76  0.54  0.63   702\n",
              "PER    0.76  0.59  0.66  1617\n",
              "ORG    0.45  0.27  0.34  1661\n",
              "LOC    0.76  0.70  0.73  1668\n",
              "total  0.69  0.52  0.59  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk0yZATbc_Xa"
      },
      "source": [
        "## ex02\n",
        "\n",
        "> Grouping of Entities. Write a function to group recognized named entities using `noun_chunks` method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together).\n",
        "\n",
        "---\n",
        "\n",
        "In this exercise I had to group the named entities using noun chunks, with the caveat that some named entities may not be part of any noun chunks. Indeed, my code tries to *intersect* the output of `doc.noun_chunks` and `doc.ents`, in such a way that all named entities are present in the output.\n",
        "\n",
        "After that, I simply run a frequency count over all groups, by simply incrementing the entry of a dictionary depending whether a certain combination is present or not.\n",
        "\n",
        "An example of result is shown below:\n",
        "\n",
        "input: `Four Africans said to vie for top U.N. post.`\n",
        " \n",
        "grouping: `[['CARDINAL', 'NORP'], ['ORG']]`\n",
        "\n",
        "counting: `{'CARDINAL_NORP': 1, 'ORG':1}`\n",
        "\n",
        "In the following output cell you can see the 15 most frequent groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3m2ONGPTUxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "eb101668-428e-45ab-8f05-1ed38a798753"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = my_tokenizer\n",
        "\n",
        "def group(sentence:str):\n",
        "  \"\"\"\n",
        "  Function to loop over all entities and noun_chunks, in order to group entities without filtering them\n",
        "  \"\"\"\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  ret = [[]]\n",
        "  last_j = -1\n",
        "  for i , entity in enumerate(doc.ents):\n",
        "    found = False\n",
        "    for j , chunk in enumerate(doc.noun_chunks):    \n",
        "      if found: continue\n",
        "      for t in chunk.ents:\n",
        "        if found: continue\n",
        "        if t == entity:\n",
        "          if last_j == j - 1:\n",
        "            ret[-1].append(t.label_)\n",
        "          else:\n",
        "            ret.append([])\n",
        "            ret[-1].append(t.label_)\n",
        "          found = True\n",
        "          last_j = j - 1\n",
        "    if found == False:\n",
        "      ret.append([])\n",
        "      ret[-1].append(entity.label_)\n",
        "  # remove eventual [] at the beginning of the ret object\n",
        "  l = []\n",
        "  for r in ret:\n",
        "    if r != []:\n",
        "      l.append(r)\n",
        "  return l\n",
        "\n",
        "def frequency_group(groups, freq):\n",
        "  \"\"\"\n",
        "  Frequency computation over groups\n",
        "  \"\"\"\n",
        "  for group in groups:\n",
        "    key = \"_\".join(group)\n",
        "    freq[key] += 1\n",
        "\n",
        "groups = []\n",
        "freq = defaultdict(int)\n",
        "for sentence in tqdm(test[:]):\n",
        "  x = \" \".join([s[0] for s in sentence])\n",
        "  my_tokenization = [s[0] for s in sentence]\n",
        "  g = group(x)\n",
        "  frequency_group(g, freq)\n",
        "  groups.append(g)\n",
        "\n",
        "pd_tbl = pd.DataFrame().from_dict(freq, orient='index', columns=[\"Count\"]).sort_values(\"Count\", ascending=False)\n",
        "pd_tbl.round(decimals=3).head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3453/3453 [00:33<00:00, 102.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CARDINAL</th>\n",
              "      <td>1395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GPE</th>\n",
              "      <td>1255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PERSON</th>\n",
              "      <td>961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DATE</th>\n",
              "      <td>904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NORP</th>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MONEY</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CARDINAL_PERSON</th>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORDINAL</th>\n",
              "      <td>108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TIME</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Count\n",
              "CARDINAL          1395\n",
              "GPE               1255\n",
              "PERSON             961\n",
              "DATE               904\n",
              "ORG                887\n",
              "NORP               288\n",
              "MONEY              147\n",
              "CARDINAL_PERSON    122\n",
              "ORDINAL            108\n",
              "TIME                75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvZVhled5Hg5"
      },
      "source": [
        "### ex03\n",
        "\n",
        "> One of the possible post-processing steps is to fix segmentation errors. Write a function that extends the entity span to cover the full noun-compounds. Make use of compound dependency relation\n",
        "\n",
        "The tecnique was presented in [this](https://www.aclweb.org/anthology/2020.ecnlp-1.1.pdf) paper. Basically what needs to be done is a simple join between tokens adjacent to a named entity in a compund relation with it, in order to  extend the entity span to cover the full noun-compound.\n",
        "\n",
        "An example of joining is presented in the following output cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "id": "gLf92-TaXzJe",
        "outputId": "58799c6d-98ce-4ef4-bd00-d506977808f0"
      },
      "source": [
        "def my_tokenizer(txt=\"\"):\n",
        "  tokens = my_tokenization\n",
        "  return spacy.tokens.Doc(nlp.vocab, tokens)\n",
        "\n",
        "def join_ne_compounds(doc):\n",
        "  new_ne = []\n",
        "  indexes_included = set() #to handle cases in which a token is in compound relation with multiple entities\n",
        "  for t in doc.ents:\n",
        "    i = t.start\n",
        "    j = t.end\n",
        "    if t.label != \"\":\n",
        "      found = False\n",
        "      for z in t:\n",
        "        if ((doc[max(i-1, 0)].head == z and doc[i-1].dep_ == \"compound\" and doc[max(i-1, 0)].ent_type_ == \"\")\n",
        "          or\n",
        "          (doc[max(i-1, 0)] == z.head and z.dep_ == \"compound\" and doc[max(i-1, 0)].ent_type_ == \"\")):\n",
        "          if i-1 not in indexes_included:\n",
        "            found = True\n",
        "            new_ne.append(Span(doc, i-1, j, t.label_))\n",
        "            indexes_included.add(i-1) #otherways I may write doc[i-1].ent_type_ = t.ent_type to embed the check naturally in the conditions already defined, but I preferred a different way to don't manually update the fields of the Token object\n",
        "            break\n",
        "        elif ((doc[min(j, len(doc)-1)].head == z and doc[min(j, len(doc)-1)].dep_ == \"compound\" and doc[min(j, len(doc)-1)].ent_type_ == \"\")\n",
        "            or\n",
        "            (doc[min(j, len(doc)-1)] == z.head and z.dep_ == \"compound\" and doc[min(j, len(doc)-1)].ent_type_ == \"\")):\n",
        "          found = True\n",
        "          new_ne.append(Span(doc, i, j+1, t.label_))\n",
        "          indexes_included.add(j)\n",
        "          break\n",
        "      if not found:\n",
        "        new_ne.append(Span(doc, i, j, t.label_))\n",
        "  doc.set_ents(new_ne)\n",
        "  return doc\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.tokenizer = my_tokenizer\n",
        "\n",
        "x = \"Other facts : As a qualifier for the 1993 World Cup finals through Europa Cup results.\"\n",
        "my_tokenization = x.split(\" \")\n",
        "doc = nlp(x)\n",
        "\n",
        "print(\"Dependecy graph of the input sentence:\\n\")\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "\n",
        "print(\"\\n\\nOriginal named entities:\")\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)\n",
        "\n",
        "#apply the algorithm\n",
        "doc = join_ne_compounds(doc)\n",
        "\n",
        "print(\"\\n\\nUpdated named entities:\")\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dependecy graph of the input sentence:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"75582b9f56b348fdbba7e4097fd77714-0\" class=\"displacy\" width=\"2675\" height=\"749.5\" direction=\"ltr\" style=\"max-width: none; height: 749.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Other</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">facts :</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">As</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">qualifier</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">1993</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">World</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Cup</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">finals</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">through</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">Europa</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">Cup</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"659.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">results.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-0\" stroke-width=\"2px\" d=\"M70,614.5 C70,527.0 195.0,527.0 195.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,616.5 L62,604.5 78,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-1\" stroke-width=\"2px\" d=\"M245,614.5 C245,2.0 2500.0,2.0 2500.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,616.5 L237,604.5 253,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-2\" stroke-width=\"2px\" d=\"M245,614.5 C245,527.0 370.0,527.0 370.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M370.0,616.5 L378.0,604.5 362.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-3\" stroke-width=\"2px\" d=\"M595,614.5 C595,527.0 720.0,527.0 720.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,616.5 L587,604.5 603,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-4\" stroke-width=\"2px\" d=\"M420,614.5 C420,439.5 725.0,439.5 725.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M725.0,616.5 L733.0,604.5 717.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-5\" stroke-width=\"2px\" d=\"M770,614.5 C770,527.0 895.0,527.0 895.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M895.0,616.5 L903.0,604.5 887.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-6\" stroke-width=\"2px\" d=\"M1120,614.5 C1120,264.5 1785.0,264.5 1785.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,616.5 L1112,604.5 1128,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-7\" stroke-width=\"2px\" d=\"M1295,614.5 C1295,352.0 1780.0,352.0 1780.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,616.5 L1287,604.5 1303,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-8\" stroke-width=\"2px\" d=\"M1470,614.5 C1470,527.0 1595.0,527.0 1595.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,616.5 L1462,604.5 1478,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-9\" stroke-width=\"2px\" d=\"M1645,614.5 C1645,527.0 1770.0,527.0 1770.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,616.5 L1637,604.5 1653,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-10\" stroke-width=\"2px\" d=\"M945,614.5 C945,177.0 1790.0,177.0 1790.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1790.0,616.5 L1798.0,604.5 1782.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-11\" stroke-width=\"2px\" d=\"M770,614.5 C770,89.5 1970.0,89.5 1970.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,616.5 L1978.0,604.5 1962.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-12\" stroke-width=\"2px\" d=\"M2170,614.5 C2170,527.0 2295.0,527.0 2295.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,616.5 L2162,604.5 2178,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-75582b9f56b348fdbba7e4097fd77714-0-13\" stroke-width=\"2px\" d=\"M1995,614.5 C1995,439.5 2300.0,439.5 2300.0,614.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-75582b9f56b348fdbba7e4097fd77714-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2300.0,616.5 L2308.0,604.5 2292.0,604.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Original named entities:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Other facts : As a qualifier for the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1993\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    World Cup\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " finals through \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Europa Cup\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " results. </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Updated named entities:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Other facts : As a qualifier for the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1993\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    World Cup finals\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " through \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Europa Cup\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              " results. </div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLYbkDdbXz8j"
      },
      "source": [
        "Basically, since `finals` is in a *compound* relation with `World Cup`, the resulting named entity will be `World Cup finals`.\n",
        "\n",
        "To implement this algorithm I used the function `doc.set_ents` provided by Spacy, passing all the named entities found in the Doc object. Standard named entities are passed as they are (`Span(doc, ne.start, ne.end, ne.label_)`), whereas for named entities that needs to be *augmented* (as described previously) I passed instead an enlarged Span (either `Span(doc, ne.start-1, ne.end, ne.label_)` or `Span(doc, ne.start, ne.end+1, ne.label_)`). Some specific sanity checks are put in place in order to avoid tokens belonging to multiple Spans, something that would result in a Spacy exception.\n",
        "\n",
        "After that, to check whether this technique was beneficial, I re-evaluated the spacy model with the conll script. Results are reported below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNUmJTgtV7k7",
        "outputId": "85d27daf-2b4d-402a-b275-d3885e37e94e"
      },
      "source": [
        "conll_pred , conll_true , ret = [] , [] , []\n",
        "for sentence in tqdm(test[:]):\n",
        "  y = [s[3] for s in sentence]\n",
        "  x = \" \".join([s[0] for s in sentence])\n",
        "  my_tokenization = [s[0] for s in sentence]\n",
        "\n",
        "  doc = join_ne_compounds(nlp(x))\n",
        "  ret.append(doc)\n",
        "\n",
        "  #evaluation\n",
        "  preds = compose_string_prediction(doc, mapper)\n",
        "  conll_pred.append([])\n",
        "  conll_true.append([])\n",
        "  for j in range(len(y)):\n",
        "    conll_pred[-1].append((sentence[j][0] , preds[j]))\n",
        "    conll_true[-1].append((sentence[j][0] , y[j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3453/3453 [00:32<00:00, 107.27it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "SEaiS484iY2l",
        "outputId": "1808890c-1532-477a-aac3-f903aa17eaf3"
      },
      "source": [
        "print(\"Original chunk-level performances:\\n\")\n",
        "pd_tbl.round(decimals=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original chunk-level performances:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.76</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.63</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.45</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.59</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          p     r     f     s\n",
              "PER    0.76  0.59  0.66  1617\n",
              "LOC    0.76  0.70  0.73  1668\n",
              "MISC   0.76  0.54  0.63   702\n",
              "ORG    0.45  0.27  0.34  1661\n",
              "total  0.69  0.52  0.59  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "s6AVIFeMie55",
        "outputId": "931dc528-acef-4f4d-a3f7-770a347f9e26"
      },
      "source": [
        "print(\"Updated chunk-level performances:\\n\")\n",
        "pd_tbl2 = pd.DataFrame().from_dict(evaluate(conll_true, conll_pred), orient='index')\n",
        "pd_tbl2.round(decimals=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated chunk-level performances:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.65</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.57</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.58</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.36</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.27</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.60</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.52</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          p     r     f     s\n",
              "PER    0.65  0.51  0.57  1617\n",
              "LOC    0.69  0.64  0.67  1668\n",
              "MISC   0.69  0.49  0.58   702\n",
              "ORG    0.36  0.22  0.27  1661\n",
              "total  0.60  0.46  0.52  5648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1976EfJNfn"
      },
      "source": [
        "Overall, applying the technique presented in [this](https://www.aclweb.org/anthology/2020.ecnlp-1.1.pdf) paper does not seem beneficial, at least considered the evaluation performed by the *conll* script."
      ]
    }
  ]
}